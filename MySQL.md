# MySQL

**一条查询语句怎么执行的？**

大体来说，MySQL可以分为Server层和存储引擎层两部分

Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。

![](./images/MySQL执行流程.png)

连接器：

```text
连接器负责跟客户端建立连接、获取权限、维持和管理连接。

通过命令或者客户端输入用户名和密码连接MySQL服务器，在完成经典的TCP握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。
- 如果用户名或密码不对，你就会收到一个"Access denied for user"的错误，然后客户端程序结束执行。
- 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。
这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。

客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数wait_timeout控制的，默认值是8小时。
```

查询缓存：

```java
MySQL拿到一个查询请求后，会先到查询缓存看看，之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。

但是大多数情况下建议不要使用查询缓存，因为查询缓存往往弊大于利。
MySQL也提供了这种“按需使用”的方式。你可以将参数query_cache_type设置成DEMAND，这样对于默认的SQL语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用SQL_CACHE显式指定，像下面这个语句一样：
mysql> select SQL_CACHE * from T where ID=10；

需要注意的是，MySQL 8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。
```

分析器：

```java
如果没有命中查询缓存，就要开始真正执行语句了。

分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。

做完“词法分析”后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。
```

优化器：

```java
经过了分析器，在开始执行之前，还要先经过优化器的处理。
优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。
```

执行器：

```text
进入执行器阶段，开始执行语句。
开始执行的时候，要先判断一下你对这个表有没有执行查询的权限，如果没有，就会返回没有权限的错误。
如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。

比如我们举个例子，表中ID字段没有索引且查询使用ID，那么执行器的执行流程是这样的：
1.调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；
2.调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
3.执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。
至此，这个语句就执行完成了。
对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。
```

**一条更新语句怎么执行的？**

你执行语句前要先连接数据库，这是连接器的工作。

在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表T上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。

接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用哪个索引。然后，执行器负责具体执行，找到这一行，然后更新。 

与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志）

具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做， 

InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写

有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为**crash-safe**。 

 **redo log是InnoDB引擎特有的日志**，而Server层也有自己的日志，称为binlog（归档日志） 

```text
注：
	因为最开始MySQL里并没有InnoDB引擎。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统——也就是redo log来实现crash-safe能力。
```

这两种日志有以下三点不同：

1. redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。
2. redo log是物理日志，记录的是“在某个数据页上做了什么修改”；
   binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”；
3. redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 

执行器和InnoDB引擎在执行这个简单的update语句时的内部流程：

```text
mysql> update T set c=c+1 where ID=1;

1. 执行器先找引擎取ID=1这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=1这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。

2. 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。

3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。

4. 执行器生成这个操作的binlog，并把binlog写入磁盘。

5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。
```

![](./images/update语句的执行流程.png)

redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数建议设置成1，这样可以保证MySQL异常重启之后数据不丢失。

sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数也建议设置成1，这样可以保证MySQL异常重启之后binlog不丢失。 



**事务隔离**

ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性） 

SQL标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）

```text
- 读未提交：一个事务还没提交时，它做的变更就能被别的事务看到。
- 读提交：一个事务提交之后，它做的变更才会被其他事务看到。
- 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
- 串行化：顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。
```

![事务的隔离性](./images/事务的隔离性.png)

四种隔离级别通过上图分析结果

```text
- 若隔离级别是“读未提交”， 则V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2。“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；
- 若隔离级别是“读提交”，则V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以， V3的值也是2。在“读提交”隔离级别下，视图是在每个SQL语句开始执行的时候创建的，访问的时候以视图的逻辑结果为准。
- 若隔离级别是“可重复读”，则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。
- 若隔离级别是“串行化”，则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是1，V3的值是2。“串行化”隔离级别下直接用加锁的方式来避免并行访问。
```

```text
注：
	在不同的隔离级别下，数据库行为是有所不同的。Oracle数据库的默认隔离级别其实就是“读提交”，因此对于一些从Oracle迁移到MySQL的应用，为保证数据库隔离级别的一致，你一定要记得将MySQL的隔离级别设置为“读提交”。
```

**事务隔离的实现**

在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。 

![回滚日志](./images/回滚日志.png)

```text
如上图，假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。
当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。同时你会发现，即使现在有另外一个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的。

注：
	回滚日志不会一直保留，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。就是当系统里没有比这个回滚日志更早的read-view的时候，回滚日志就会被删除。

建议：
	尽量不要使用长事务，长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。
	在MySQL 5.5及以前的版本，回滚日志是跟数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。
```

**事务的启动方式**

MySQL的事务启动方式有以下两种：

1. 显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback
2. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。 

```text
注：
	建议使用set autocommit=1, 通过显式语句的方式来启动事务。
	在autocommit为1的情况下，用begin显式启动的事务，如果执行commit则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行begin语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。
```



**索引**

索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。

**索引的常见模型**

1. 哈希表

   ```text
   一种以键-值（key-value）存储数据的结构，我们只要输入待查找的值即key，就可以找到其对应的值即Value。
   好处是增加新的数据时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。
   所以，哈希表这种结构适用于只有等值查询的场景，比如Memcached及其他一些NoSQL引擎。而有序数组在等值查询和范围查询场景中的性能就都非常优秀。
   ```

2. 有序数组索引

   ```text
   有序数组就是按照某字段递增的顺序保存的。这时候如果你要查某个字段对应的数据，用二分法就可以快速得到，这个时间复杂度是O(log(N))。
   仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。
   所以，有序数组索引只适用于静态存储引擎，比如你要保存的是2017年某个城市的所有人口信息，这类不会再修改的数据。
   ```

3. 二叉搜索树

   ```text
   二叉树虽然是搜索效率最高的，但是实际上大多数数据库存储却并不使用二叉树，其原因是因为索引并不只存在内存中，而且还要写入磁盘。
   举个例子：
    可以想象一下一棵100万节点的平衡二叉树，树高20。一次查询可能需要访问20个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要10 ms左右的寻址时间。也就是说，对于一个100万行的表，如果使用二叉树来存储，单独访问一个行可能需要20个10 ms的时间，这个查询可真够慢的。
   
   为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N叉”树。这里，“N叉”树中的“N”取决于数据块的大小。
   ```
   



```text
不管是哈希还是有序数组，或者N叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，跳表、LSM树等数据结构也被用于引擎设计中
总之数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。
```



**InnoDB 的索引模型**

在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为InnoDB使用了B+树索引模型，所以数据都是存储在B+树中的。

 每个索引在innoDB里面都对应的有一颗B+树

```text
create table T(
id int primary key, 
k int not null, 
index (k))engine=InnoDB;

举例：上表主键列key和k上有索引
row1~row5的(ID,k)值分别为(100,1)、(200,2)、(300,3)、(500,5)和(600,6)
对应有以下的两颗B+树
```

![innoDB索引结构](./images/innoDB索引结构.png)

```text
根据叶子节点的内容，索引类型分为主键索引和非主键索引。

主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。
非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。

例如：SELECT * FROM t WHERE k=5
首先根据普通索引找到主键的值，在根据主键的值在ID索引树中搜索一次，这个过程称为回表。
即：基于非主键索引树需要多扫描一颗索引树，因此我们在应用中尽量使用主键搜索。
```

**索引维护**

B+树为了保证有序性，在插入或着删除数据的时候会对树进行维护。在此过程中会出现两种情况：页分裂和也合并，这两种情况都会有性能损耗。但是如果是自增主键就不会出现这两种情况。

在自增主键的插入数据模式中，每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。然而有业务的字段作为主键，则往往不容易保证插入的有序性，这样写数据的成本相对较高。除了考虑性能外，在非主键索引树叶子结点存储的是主键的值，如果主键采用的是很长的字符串，将会占用很多的存储空间，而如果使用整数类型作为主键，只占用4个字节，显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间就越小
索引从性能和存储空间考虑，往往自增主键索引是更合理的选择。

但是也可以采用业务字段作为索引，例如以下场景：

```text
1. 只有一个索引
2. 该索引必须是唯一索引

由于没有其他索引，所以也不用考虑其他索引的叶子节点大小问题。
这时候应该优先考虑“尽量使用主键查询”的原则，直接将该字段设为主键，避免了每次查询需要搜索两棵树
```

**覆盖索引**

```text
SELECT * FROM T WHERE k BETWEEN 3 AND 5;
SELECT ID FROM T WHERE K BETWEEN 3 AND 5;
以上两条SQL的执行流程有所不同：
第一条：
	1. 在k索引树上找到3对应的ID值，再到ID索引树中搜索对应的行
	2. 再到k索引树取到下一个值为5，在回到ID索引树中搜索对应的行
	3. 再回到k索引树取下一个值为6，不满足条件，结束循环
在这个过程中，回到主键索引树搜索的过程，我们称为回表。这个查询过程读了k索引树的3条记录，回表了两次。
第二条：
查询结果已经在k索引树上了，因此可以直接提供查询结果，不需要回表，即这个查询，索引k已经"覆盖了"我们查询的需求，称为覆盖索引。

建议：
	由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。
```

**最左前缀原则**

B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。那么在建立联合索引的时候，如何安排索引内的字段顺序呢，该评估标准就是**索引的复用能力**， 因为可以支持最左前缀，所以当已经有了(a,b)这个联合索引后，一般就不需要单独在a上建立索引了。因此，**第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。** 那么，如果既有联合查询，又有基于a、b各自的查询，但查询条件里面只有b的语句，是无法使用(a,b)这个联合索引的，这时候你不得不维护另外一个索引，也就是说需要同时维护(a,b)、(b) 这两个索引。这时候，我们要**考虑的原则就是空间**了。比如以下情况，a字段是比b字段大的 ，那我就建议你创建一个（a,b)的联合索引和一个(b)的单字段索引。

**索引下推**

对于那些不符合左前缀

```text
例如：
联合索引(a,b,c)，如果既有条件a也有条件c，那么根据前缀规则则会通过该索引搜索树根据条件a搜索结果，然后在MySQL5.6之前，只能再进行回表查询，到主键索引上找出数据行，在进行对比条件c
而在MySQL5.6及以后就引入了索引下推优化，可以在索引遍历过程中，对索引中	包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表的次数
也就是例子中的判断条件a，同时也判断条件c，对于不满足的直接跳过，进而可以减少回表的次数
```



```text
注：
为什么需要重建索引?
索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。

	对于InnoDB表T，如果你要重建索引k，你的两个SQL语句可以这么写：
        alter table T drop index k;
        alter table T add index(k);
    重建非主键索引是合理的，可以达到省空间的目的。
    
    如果重建主键索引，可以如下方式：
        alter table T drop primary key;
        alter table T add primary key(id);
    重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。
    这两个语句，你可以用这个语句代替 ： alter table T engine=InnoDB。
```

**全局锁和表锁**

根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类

**全局锁**

全局锁就是对整个数据库实例加锁，MySQL提供了一个加全局读锁的方法，命令是 `Flush tables with read lock (FTWRL)`。使用这个命令之后其他例如数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句等都会使线程阻塞。

全局锁的典型使用场景是做**全库逻辑备份**。
但是让整个库只读，会有以下缺点：
1. 如果是在主库上备份，那么在备份期间不能执行更新类的语句，业务流程基本停止。
2. 如果是在从库上备份，那么在备份期间不能执行主库同步过来的binlog，会导致主从延迟。

MySQL数据库自带的逻辑备份工具是mysqldump。当mysqldump使用参数`–single-transaction`的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。**但是前提是引擎要支持这个隔离级别(可重复读)**。
例如，对于MyISAM这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用FTWRL命令了。

```text
注：
    single-transaction方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过FTWRL方法。这往往是DBA要求业务开发人员使用InnoDB替代MyISAM的原因之一。

尽量不使用set global readonly=true的方式使全库只读，原因如下：
1. 在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大
2. 在异常处理机制上会有所不同，执行FTWRL命令之后如果客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。
```

**表级锁**

MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。

表锁的语法是 lock tables … read/write。与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

```text
例如，如果在某个线程A中执行lock tables t1 read, t2 write; 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，也不能访问其他表。

对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。

表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有lock tables这样的语句，比较可能的情况是：
- 要么是系统现在还在用MyISAM这类不支持事务的引擎，那要安排升级换引擎；
- 要么是引擎升级了，但是代码还没升级。最后业务开发就是把lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。
```

MySQL 5.5版本中引入了另一类表级的锁是MDL(metadata Lock)，MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。
- 读锁之间不互斥，因此可以有多个线程同时对一张表增删改查。
- 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

```text
例如一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上。
当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。

虽然MDL锁是系统默认会加的，但却要注意MDL会直到事务提交才释放，所以在做表的结构变更的时候，要注意不要导致锁住线上查询和更新。
```

**行锁**

行锁就是针对数据表中行记录的锁。MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB是支持行锁

```text
两阶段锁协议

在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。

知道了两阶段锁，使用事务的时候需要注意的是：如果事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的行锁的申请时机尽量往后放。这样一来最可能影响并发度的行锁在事务中待的时间就是最少，这就最大程度地减少了事务之间的锁等待，提升了并发度。
```

**死锁和死锁检测**

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。

两种策略：

1. 直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置，在InnoDB中，innodb_lock_wait_timeout的默认值是50

2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。innodb_deadlock_detect的默认值本身就是on

```text
主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。

每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。如果所有事务都要更新同一行，每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。因此，你就会看到CPU利用率很高，但是每秒却执行不了几个事务。

所以这种热点行更新导致的性能问题的症结在于，死锁检测要耗费大量的CPU资源。

三种解决方案：
1. 如果能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉，带有一定的风险性。
2. 控制并发度。如果你有中间件，可以考虑在中间件实现；如果能修改MySQL源码，基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了；
3. 可以考虑通过将一行改成逻辑上的多行来减少锁冲突。每次要更改该数据行的时候，随机选其中一条记录来更新。这样每次冲突概率变成原来的1/10，可以减少锁等待个数，也就减少了死锁检测的CPU消耗。
```